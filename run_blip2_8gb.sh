#!/usr/bin/env bash

# ==============================================
# BLIP-2 èµ·å‹•ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆ8GB VRAMå‘ã‘ãƒ»VLMå°‚ç”¨ï¼‰
# transformers + bitsandbytes ã«ã‚ˆã‚‹ 8bit/4bit é‡å­åŒ–å¯¾å¿œ
# ä¾‹: bash run_blip2_8gb.sh [ãƒ¢ãƒ‡ãƒ«å] [8bit|4bit] [ç”»åƒãƒ‘ã‚¹] [è³ªå•]
# ==============================================

set -euo pipefail

MODEL_ID=${1:-"Salesforce/blip2-opt-2.7b"}
QUANT=${2:-"8bit"}           # 8bit | 4bit
IMAGE_PATH=${3:-""}          # ç”»åƒãƒ‘ã‚¹ï¼ˆçœç•¥å¯ï¼‰
QUESTION=${4:-"Describe the image."}

HOST="localhost"
PORT=0  # ã‚µãƒ¼ãƒã¯ç«‹ã¦ãšã€CLIå®Ÿè¡Œã®ã¿ï¼ˆå¿…è¦ãªã‚‰å°†æ¥æ‹¡å¼µï¼‰

echo "ğŸš€ BLIP-2 èµ·å‹• (VLMå°‚ç”¨)"
echo "  ğŸ”¹ MODEL_ID : $MODEL_ID"
echo "  ğŸ”¹ QUANT    : $QUANT"
if [[ -n "$IMAGE_PATH" ]]; then
  echo "  ğŸ”¹ IMAGE    : $IMAGE_PATH"
else
  echo "  ğŸ”¹ IMAGE    : (æœªæŒ‡å®š)"
fi
echo "  ğŸ”¹ QUESTION : $QUESTION"

# ========= ãƒ¡ãƒ¢ãƒª/å®Ÿè¡Œç’°å¢ƒ è¨­å®š =========
export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True
export CUDA_VISIBLE_DEVICES=${CUDA_VISIBLE_DEVICES:-0}

# ========= ä¾å­˜é–¢ä¿‚ãƒã‚§ãƒƒã‚¯ =========
echo "ğŸ” ä¾å­˜é–¢ä¿‚ãƒã‚§ãƒƒã‚¯: torch, transformers, bitsandbytes, pillow"
uv run python - <<'PY' 2>/dev/null || { echo "âŒ ä¾å­˜é–¢ä¿‚ãƒã‚§ãƒƒã‚¯ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ä¸Šè¨˜ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚"; exit 1; }
import importlib, sys
required = ["torch", "transformers", "bitsandbytes", "PIL"]
missing = []
for m in required:
    try:
        importlib.import_module(m)
    except Exception:
        missing.append(m)
if missing:
    print("âŒ ä¾å­˜é–¢ä¿‚ãŒä¸è¶³ã—ã¦ã„ã¾ã™:", ", ".join(missing))
    print("ğŸ’¡ ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã§è¿½åŠ ã—ã¦ãã ã•ã„:")
    print("   uv add torch torchvision pillow transformers bitsandbytes accelerate")
    sys.exit(1)
print("âœ… ä¾å­˜é–¢ä¿‚OK")
PY

# ========= å®Ÿè¡Œ =========
echo "ğŸ§  ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã€CLIã§ç”»åƒã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³/VQAã‚’å®Ÿè¡Œã—ã¾ã™..."

UV_CACHE_DIR=${UV_CACHE_DIR:-"./hf_models"}
OFFLOAD_DIR=${OFFLOAD_DIR:-"./offload"}
mkdir -p "$UV_CACHE_DIR" "$OFFLOAD_DIR"

UV_MODEL_ID="$MODEL_ID" \
UV_QUANT="$QUANT" \
UV_IMAGE_PATH="$IMAGE_PATH" \
UV_QUESTION="$QUESTION" \
UV_CACHE_DIR="$UV_CACHE_DIR" \
UV_OFFLOAD_DIR="$OFFLOAD_DIR" \
uv run python - <<'PY'
import os
import sys
import base64
from io import BytesIO

import torch
from PIL import Image
from transformers import Blip2Processor, Blip2ForConditionalGeneration, BitsAndBytesConfig


def print_banner(message: str) -> None:
    print(message, flush=True)


def load_image(path: str | None) -> Image.Image:
    if path and os.path.exists(path):
        return Image.open(path).convert("RGB")
    # æœ€å°ã®ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ç”»åƒ (1x1 PNG, white)
    tiny_png_base64 = (
        "iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVR4nGMAAQAABQAB"
        "J1N6WQAAAABJRU5ErkJggg=="
    )
    data = base64.b64decode(tiny_png_base64)
    return Image.open(BytesIO(data)).convert("RGB")


model_id = os.environ.get("UV_MODEL_ID", "Salesforce/blip2-opt-2.7b")
quant_mode = os.environ.get("UV_QUANT", "8bit").lower()
image_path = os.environ.get("UV_IMAGE_PATH", "")
question = os.environ.get("UV_QUESTION", "Describe the image.")
cache_dir = os.environ.get("UV_CACHE_DIR", "./hf_models")
offload_dir = os.environ.get("UV_OFFLOAD_DIR", "./offload")

if quant_mode not in {"8bit", "4bit"}:
    print(f"[ERROR] ç„¡åŠ¹ãªé‡å­åŒ–æŒ‡å®š: {quant_mode}. 8bit ã‹ 4bit ã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚", file=sys.stderr)
    sys.exit(2)

print_banner("ğŸ”§ é‡å­åŒ–è¨­å®šã‚’é©ç”¨ä¸­...")
if quant_mode == "8bit":
    bnb_config = BitsAndBytesConfig(load_in_8bit=True)
else:
    bnb_config = BitsAndBytesConfig(
        load_in_4bit=True,
        bnb_4bit_quant_type="nf4",
        bnb_4bit_use_double_quant=True,
        bnb_4bit_compute_dtype=torch.float16,
    )

print_banner("ğŸ“¦ ãƒ¢ãƒ‡ãƒ«/ãƒ—ãƒ­ã‚»ãƒƒã‚µã‚’èª­ã¿è¾¼ã¿ä¸­...")
processor = Blip2Processor.from_pretrained(model_id, cache_dir=cache_dir)
model = Blip2ForConditionalGeneration.from_pretrained(
    model_id,
    cache_dir=cache_dir,
    torch_dtype=torch.float16,
    device_map="auto",
    quantization_config=bnb_config,
    offload_folder=offload_dir,
)

image = load_image(image_path)

print_banner("ğŸ“ æ¨è«–ã‚’å®Ÿè¡Œä¸­...")
inputs = processor(images=image, text=question, return_tensors="pt")

# device_map="auto" ã‚’ç”¨ã„ã¦ã„ã‚‹ãŸã‚ã€å…¥åŠ›ã¯CPUã®ã¾ã¾ã§OKï¼ˆAccelerateãŒè‡ªå‹•ã§å‰²å½“ï¼‰
with torch.inference_mode():
    generated_ids = model.generate(**inputs, max_new_tokens=64)
    generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0].strip()

print("\n================ RESULT ================")
print(f"Question: {question}")
if image_path:
    print(f"Image   : {image_path}")
else:
    print("Image   : (placeholder 1x1)")
print(f"Answer  : {generated_text}")
print("=======================================\n")

print("âœ… å®Œäº†ã€‚åˆ¥ã®å…¥åŠ›ã§å†å®Ÿè¡Œã™ã‚‹å ´åˆã¯å¼•æ•°ã‚’å¤‰ãˆã¦ã‚³ãƒãƒ³ãƒ‰ã‚’å†åº¦å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
PY

exit_code=$?
if [[ $exit_code -ne 0 ]]; then
  echo "âŒ å®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ (exit: $exit_code)"
  exit $exit_code
fi

echo "ğŸ‰ æ­£å¸¸çµ‚äº†"

echo "\nğŸ“‹ ä½¿ã„æ–¹ã®ä¾‹:"
echo "  1) 8bité‡å­åŒ–ãƒ»ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ç”Ÿæˆ:"
echo "     bash run_blip2_8gb.sh 'Salesforce/blip2-opt-2.7b' 8bit ./path/to/image.jpg 'Describe the image.'"
echo ""
echo "  2) 4bité‡å­åŒ–(NF4)ãƒ»VQA:"
echo "     bash run_blip2_8gb.sh 'Salesforce/blip2-opt-2.7b' 4bit ./path/to/image.jpg 'What is in the picture?'"
echo ""
echo "  3) ç”»åƒçœç•¥ï¼ˆãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ç”»åƒã§å‹•ä½œç¢ºèªã®ã¿ï¼‰:"
echo "     bash run_blip2_8gb.sh 'Salesforce/blip2-opt-2.7b' 8bit '' 'Hello'"


